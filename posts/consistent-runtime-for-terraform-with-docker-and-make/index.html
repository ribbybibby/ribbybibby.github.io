<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>HOW TO: Create a consistent runtime for Terraform with Docker and make :: ribbybibby — A simple, retro theme for Hugo</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="Inevitably, when you start using a shared Terraform code base between more than two or three people you have to start introducing measures to ensure consistency of approach across your team.
For instance, how do you make sure everyone is running the same version of Terraform? Or that they’re initializing the backend properly? And if you’re using null_resource resources or provisioner blocks to execute scripts out-of-band, you have to ensure everyone has the right dependencies installed."/>
<meta name="keywords" content=""/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="/posts/consistent-runtime-for-terraform-with-docker-and-make/" />


<link rel="stylesheet" href="/assets/style.css">



<link rel="stylesheet" href="/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="/img/apple-touch-icon-144-precomposed.png">

<link rel="shortcut icon" href="/img/favicon/orange.png">



<meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="HOW TO: Create a consistent runtime for Terraform with Docker and make :: ribbybibby — A simple, retro theme for Hugo" />
<meta name="twitter:description" content="Inevitably, when you start using a shared Terraform code base between more than two or three people you have to start introducing measures to ensure consistency of approach across your team.
For instance, how do you make sure everyone is running the same version of Terraform? Or that they’re initializing the backend properly? And if you’re using null_resource resources or provisioner blocks to execute scripts out-of-band, you have to ensure everyone has the right dependencies installed." />
<meta name="twitter:site" content="/" />
<meta name="twitter:creator" content="" />
<meta name="twitter:image" content="">


<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="HOW TO: Create a consistent runtime for Terraform with Docker and make :: ribbybibby — A simple, retro theme for Hugo">
<meta property="og:description" content="Inevitably, when you start using a shared Terraform code base between more than two or three people you have to start introducing measures to ensure consistency of approach across your team.
For instance, how do you make sure everyone is running the same version of Terraform? Or that they’re initializing the backend properly? And if you’re using null_resource resources or provisioner blocks to execute scripts out-of-band, you have to ensure everyone has the right dependencies installed." />
<meta property="og:url" content="/posts/consistent-runtime-for-terraform-with-docker-and-make/" />
<meta property="og:site_name" content="HOW TO: Create a consistent runtime for Terraform with Docker and make" />
<meta property="og:image" content="">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">

<meta property="article:published_time" content="2019-05-02 18:18:51 &#43;0100 BST" />











</head>
<body class="">


<div class="container full">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    ribbybibby
  </div>
</a>

    </div>
    <div class="menu-trigger">menu</div>
  </div>
  
    <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/about">About</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/about">About</a></li>
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="/posts/consistent-runtime-for-terraform-with-docker-and-make/">HOW TO: Create a consistent runtime for Terraform with Docker and make</a></h1>
  <div class="post-meta">
    <span class="post-date">
      2019-05-02
    </span>
    
  </div>

  

  

  <div class="post-content">
    

<p>Inevitably, when you start using a shared Terraform code base between more than two or three people you have to start introducing measures to ensure consistency of approach across your team.</p>

<p>For instance, how do you make sure everyone is running the same version of Terraform? Or that they’re initializing the backend properly? And if you’re using <code>null_resource</code> resources or <code>provisioner</code> blocks to execute scripts out-of-band, you have to ensure everyone has the right dependencies installed.</p>

<p>This is one approach I’ve used to address these problems, using a Docker image and a Makefile to provide a consistent environment for running Terraform locally and a wrapper around Terraform to make sure the whole team are executing it in the same way.</p>

<h3 id="requirements">Requirements</h3>

<ul>
<li>Relatively up to date versions of Docker and docker-compose</li>
</ul>

<h3 id="repository-structure">Repository structure</h3>

<p>For the purposes of this post, let’s assume your Terraform code is all versioned in one repository with a structure similar to this:</p>

<pre><code>.
├── README.md
└── terraform
    ├── project1
    │   ├── main.tf
    │   ├── outputs.tf
    │   ├── variables.tf
    │   └── vars
    │       ├── dev.tfvars
    │       ├── prod.tfvars
    │       └── staging.tfvars
    └── project2
        ├── main.tf
        ├── outputs.tf
        ├── variables.tf
        └── vars
            ├── dev.tfvars
            ├── prod.tfvars
            └── staging.tfvars
</code></pre>

<p>There’s a folder for each project in your organization (<code>.terraform/</code>) containing <code>.tf</code> files and a <code>.tfvars</code> file for each environment. This is my preferred way to partition my Terraform code, but if yours is different it doesn&rsquo;t make much difference in the context of this guide.</p>

<h3 id="dockerfile">Dockerfile</h3>

<p>The first thing I&rsquo;m going to add is a <code>Dockerfile</code> to the root of the repository:</p>

<pre><code class="language-Dockerfile">FROM alpine:3.8

ENV TERRAFORM_VERSION=0.11.13
ENV AWSCLI_VERSION=1.14.10

RUN apk add --update bash make python python-dev py-pip build-base unzip ca-certificates jq

RUN pip install awscli==$AWSCLI_VERSION --upgrade

RUN wget https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip \
    &amp;&amp; unzip terraform_${TERRAFORM_VERSION}_linux_amd64.zip -d /usr/local/bin/

WORKDIR /terraform

ENTRYPOINT [&quot;/bin/bash&quot;]
</code></pre>

<p>Pretty simple. Essentially all I’m doing here is downloading my desired version of the Terraform binary to /usr/local/bin inside a simple alpine:3.8 image.</p>

<p>You’ll also notice that that I install <code>awscli</code> and <code>jq</code>. This is because in this particular code base I intend to run a few scripts out-of-band that require them. That&rsquo;s why we&rsquo;re using Docker: so we can be certain that when we run Terraform, we have everything we need, no matter who&rsquo;s running it or where.</p>

<h3 id="docker-compose">docker-compose</h3>

<p>You might have noticed that I didn’t copy the contents of my <code>./terraform</code> directory into the Docker image. That&rsquo;s because I&rsquo;m going to mount it instead so that I can make changes to the files on my local filesystem but then apply them from within the running Docker container.</p>

<p>If you were including this repo inside a CI/CD pipeline, you might choose to copy the dir in to provide you with a versioned artifact. On the other hand, in that situation I think there&rsquo;s still something to be said for versioning your terraform code and what is essentially your terraform binary separately. More on that later.</p>

<p>I create <code>docker-compose.yml</code> next to my <code>Dockerfile</code>:</p>

<pre><code class="language-yaml">version: '3'
services:
  terraform:
    build: .
    tty: true
    stdin_open: true
    environment:
      - AWS_DEFAULT_REGION=eu-west-2
    volumes:
      - ./terraform:/terraform
      - ~/.aws:/root/.aws
</code></pre>

<p>Under volumes you can see I bind the <code>./terraform</code> directory to <code>/terraform</code> on the container. I also mount the <code>~/.aws</code> directory and set the <code>AWS_DEFAULT_REGION</code> environment variable so that the AWS credentials of the user will be available and the resources in the right region will be targeted (this is all assuming your Terraform code uses AWS resources, of course).</p>

<p>The <code>tty</code> and <code>stdin_open</code> bools set to <code>true</code> ensure than when I eventually run the container, I get an interactive bash shell and I can cd to one of my project directories, see all the code and run Terraform if I wish.</p>

<pre><code>$ docker-compose run terraform
bash-4.4# cd project1
bash-4.4# ls 
main.tf  outputs.tf  variables.tf  vars
bash-4.4# terraform get
bash-4.4# terraform init

Initializing the backend..
</code></pre>

<h2 id="makefile">Makefile</h2>

<p>This <code>Makefile</code> wraps around the plan and apply commands, making sure they&rsquo;re ran in a consistent fashion.</p>

<pre><code class="language-Makefile">ENVIRONMENT := dev
PROJECT := $(notdir $(shell pwd))
TF_BUCKET := org-tfstate-${ENVIRONMENT}

.PHONY: update init plan apply

all: update 

update:
	@terraform get -update .

init: update
	@terraform init \
        -backend=true \
        -backend-config=&quot;bucket=$(TF_BUCKET)&quot; \
        -backend-config=&quot;key=$(PROJECT).tfstate&quot; .

plan: init
	@-rm -f ./plan.tfout
	@terraform plan \
        -refresh=true \
        -out=./plan.tfout \
        -var-file=vars/$(ENVIRONMENT).tfvars $(ARGS) .

apply: init
	@terraform apply ./plan.tfout
	@-rm -f ./plan.tfout
</code></pre>

<p>By default the <code>Makefile</code> targets the dev environment. This can be overriden by supplying the <code>ENVIRONMENT</code> variable when <code>make</code> is ran:</p>

<pre><code>$ docker-compose run terraform
bash-4.4# cd project1
bash-4.4# make plan ENVIRONMENT=prod
</code></pre>

<p>Additionally, if you want to append extra arguments to <code>plan</code> you can do so with <code>ARGS</code>:</p>

<pre><code>bash-4.4# make plan ARGS=&quot;-target=aws_s3_bucket.example&quot;
</code></pre>

<p>You can place the <code>Makefile</code> inside each project directory, alongside the <code>.tf</code> files. Or, what I prefer to do is to put it at the root of the repository as <code>common.makefile</code> and refer back to it with an <code>include</code> statement in a <code>Makefile</code> in each project. This avoids unnecessary duplication:</p>

<pre><code class="language-Makefile">include ../../common.makefile
</code></pre>

<p>The structure now looks like this:</p>

<pre><code>.
├── common.makefile
├── docker-compose.yml
├── Dockerfile
├── README.md
└── terraform
    ├── project1
    │   ├── main.tf
    │   ├── Makefile
    │   ├── outputs.tf
    │   ├── variables.tf
    │   └── vars
    │       ├── dev.tfvars
    │       ├── prod.tfvars
    │       └── staging.tfvars
    └── project2
        ├── main.tf
        ├── Makefile
        ├── outputs.tf
        ├── variables.tf
        └── vars
            ├── dev.tfvars
            ├── prod.tfvars
            └── staging.tfvars
</code></pre>

<h2 id="continuous-deployment">Continuous Deployment</h2>

<p>This guide has assumed, so far, that individual team members are running Terraform to update infrastructure. However, when your Terraform deployment reaches a certain level of sophistication or your team reaches a size where it&rsquo;s becoming hard to keep track of which changes have been deployed to which environment, you might start to consider running Terraform with a CI/CD solution.</p>

<p>There are numerous ways to implement this but my recommendation would be to separate the Dockerfile into it&rsquo;s own repository and version it separately to your Terraform code.</p>

<p>Then, as part of your pipeline&rsquo;s deployment phase, you could run something like the following from within a project root module:</p>

<pre><code>$ docker run --rm -it -v .:/terraform -e AWS_PROFILE=$AWS_PROFILE myorg/terraform:v0.0.4 make plan
$ docker run --rm -it -v .:/terraform -e AWS_PROFILE=$AWS_PROFILE myorg/terraform:v0.0.4 make apply
</code></pre>

<p>This mounts the project dir in the container and runs <code>plan</code> and <code>apply</code>. It also passes the <code>AWS_PROFILE</code> environment variable from your CI environment to the container. There&rsquo;s obviously endless bespoke configuration you could add here.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This post gives you one approach to running terraform consistently that I&rsquo;ve used with great success in a number of different organisations to great success. I&rsquo;d love to hear from anyone doing anything similar, or dissimilar, to achieve the same ends.</p>

  </div>
  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2019 Powered by <a href="http://gohugo.io">Hugo</a></span>
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
    
  </div>
</footer>

<script src="/assets/main.js"></script>
<script src="/assets/prism.js"></script>





  
</div>

</body>
</html>
